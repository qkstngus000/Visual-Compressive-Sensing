{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47525857-5060-4cc0-96bb-f7c9455d1f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.models.weights import V1_weights, sensilla_weights, classical_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815479d9-b743-448d-b759-78b2b254d270",
   "metadata": {},
   "source": [
    "### V1 init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259b6a43-bf48-4e88-99e3-9e5f7b4f4d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def V1_init(layer, size, spatial_freq, center=None, scale=1., bias=False, seed=None):\n",
    "    \"\"\"\n",
    "    Initialize weights of a Conv2d layer according to receptive fields of V1.\n",
    "    Currently, only works when the number of input channels equals 1. The bias\n",
    "    is turned off.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    layer: torch.nn.Conv2d layer\n",
    "        Layer that will be initialized\n",
    "        \n",
    "    size : float\n",
    "        Determines the size of the random weights\n",
    "\n",
    "    spatial_freq : float\n",
    "        Determines the spatial frequency of the random weights \n",
    "\n",
    "    center: tuple of shape (2, 1), default = None\n",
    "        Location of the center of the random weights\n",
    "        With default value, the centers uniformly cover the RF space\n",
    "\n",
    "    scale: float, default=1\n",
    "        Normalization factor for Tr norm of cov matrix\n",
    "        \n",
    "    bias: Bool, default=False\n",
    "        The bias of the convolutional layer\n",
    "\n",
    "    seed : int, default=None\n",
    "        Used to set the seed when generating random weights.\n",
    "    \"\"\"\n",
    "    classname = layer.__class__.__name__\n",
    "    assert classname.find('Conv2d') != -1,'This init only works for conv2d layers'\n",
    "    assert layer.in_channels == 1, 'This init only works when image has 1 input channel'\n",
    "    out_channels, in_channels, xdim, ydim = layer.weight.shape  \n",
    "    v1_weight =  V1_weights(out_channels, (xdim, ydim), size, spatial_freq, center, scale, seed=seed)\n",
    "    layer.weight.data = Tensor(v1_weight.reshape(out_channels, 1, xdim, ydim))\n",
    "    if bias == False:\n",
    "        layer.bias = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df204fc5-00e9-47db-b7e0-6f400caf389a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class V1_mnist_RFNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Random Feature network to classify MNIST images. The first layer is initialized from GP\n",
    "    with covariance inspired by V1.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim, size, spatial_freq, center=None, scale=1, bias=False, seed=None):\n",
    "        super(V1_mnist_RFNet, self).__init__()\n",
    "        self.v1_layer = nn.Conv2d(in_channels=1, out_channels=hidden_dim, kernel_size=28) \n",
    "        self.clf = nn.Conv2d(in_channels=hidden_dim, out_channels=10, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # initialize the first layer\n",
    "        V1_init(self.v1_layer, size, spatial_freq, center, scale, bias, seed)\n",
    "        self.v1_layer.weight.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.v1_layer(x))\n",
    "        beta = self.clf(h)\n",
    "        return beta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6972bc8-8abd-40ad-90d3-52a272cd32dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 10])\n"
     ]
    }
   ],
   "source": [
    "# check the init\n",
    "train = torch.randn((1000, 1, 28, 28))\n",
    "out_channels = 20\n",
    "W = nn.Conv2d(1, out_channels, kernel_size=28)\n",
    "W.weight.requires_grad = False\n",
    "output = W(train)\n",
    "\n",
    "\n",
    "# check the model\n",
    "hidden_size, s, f, center, seed = 100, 5, 2, (16, 16), 20\n",
    "model = V1_mnist_RFNet(hidden_size, s, f, center, seed=seed)\n",
    "output = model(train)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d956866e-7877-4c0d-8441-55ed0a875d26",
   "metadata": {},
   "source": [
    "### sensilla init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab12c6a8-0adb-4eb0-9f7d-2ac28f501243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensilla_init(layer, lowcut, highcut, decay_coef=np.inf, scale=1, bias=False, seed=None):\n",
    "    \"\"\"\n",
    "    Initialize weights of a Linear layer according to STAs of insect sensilla.\n",
    "    The bias is turned off by default.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    layer: torch.nn.Linear layer\n",
    "        Layer that will be initialized\n",
    "\n",
    "    lowcut: int\n",
    "        Low end of the frequency band. \n",
    "\n",
    "    highcut: int\n",
    "        High end of the frequency band.\n",
    "        \n",
    "    decay_coef : float, default=np.inf\n",
    "        controls the how fast the random features decay\n",
    "        with default value, the weights do not decay\n",
    "        \n",
    "    scale: float, default=1\n",
    "        Normalization factor for Tr norm of cov matrix\n",
    "        \n",
    "    bias: Bool, default=False\n",
    "        The bias of the Linear layer\n",
    "    \n",
    "    seed : int, default=None\n",
    "        Used to set the seed when generating random weights.\n",
    "    \n",
    "    \"\"\"\n",
    "    classname = layer.__class__.__name__\n",
    "    assert classname.find('Linear') != -1,'This init only works for Linear layers'\n",
    "    out_features, in_features = layer.weight.shape\n",
    "    sensilla_weight = sensilla_weights(out_features, in_features, lowcut, highcut, decay_coef, scale, seed)\n",
    "    layer.weight.data = Tensor(sensilla_weight)\n",
    "    if bias == False:\n",
    "        layer.bias = None\n",
    "    \n",
    "\n",
    "class sensilla_RFNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Random Feature network to classify time-series. The first layer is initialized from GP\n",
    "    with covariance inspired by mechanosensory sensilla.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, \n",
    "                 lowcut, highcut, decay_coef=np.inf, scale=1, bias=False, seed=None):\n",
    "        super(sensilla_RFNet, self).__init__()\n",
    "        self.sensilla_layer = nn.Linear(in_features=input_dim, out_features=hidden_dim) \n",
    "        self.clf = nn.Linear(in_features=hidden_dim, out_features=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # initialize the first layer\n",
    "        sensilla_init(self.sensilla_layer, lowcut, highcut, decay_coef, scale, bias, seed)\n",
    "        self.sensilla_layer.weight.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.sensilla_layer(x))\n",
    "        beta = self.clf(h)\n",
    "        return beta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "220d3720-6e1d-4e62-a217-69de5d9aaa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "## check the init\n",
    "input_dim = 1600\n",
    "train = torch.randn(20, input_dim)\n",
    "W = nn.Linear(input_dim, 100)\n",
    "lowcut, highcut, decay_coef = 2, 8, 22\n",
    "sensilla_init(W, lowcut, highcut, decay_coef)\n",
    "output = W(train)\n",
    "\n",
    "## check the model\n",
    "hidden_size = 100\n",
    "model = sensilla_RFNet(input_dim, hidden_size, lowcut, highcut, decay_coef)\n",
    "output = model(train)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843cfad0-99fd-4564-bb39-7b66263e29d4",
   "metadata": {},
   "source": [
    "### classical init\n",
    "Init with diagonal covariance GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab7ea96-cf3f-4aa8-9a39-4f8870a59a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classical_init(layer, scale=1, bias=False, seed=None):\n",
    "    \"\"\"\n",
    "    Inialize weights of a Linear layer or convolutional layer according to\n",
    "    GP with diagonal covariance. \n",
    "    \n",
    "    The bias is turned off by default.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    layer: torch.nn.Linear layer\n",
    "        Layer that will be initialized\n",
    "        \n",
    "    scale: float, default=1\n",
    "        Normalization factor for Tr norm of cov matrix\n",
    "        \n",
    "    bias: Bool, default=False\n",
    "        The bias of the Linear layer\n",
    "    \n",
    "    seed : int, default=None\n",
    "        Used to set the seed when generating random weights.\n",
    "\n",
    "    \"\"\"\n",
    "    classname = layer.__class__.__name__\n",
    "    assert classname.find('Linear') != -1 or classname.find('Conv2d') != -1, 'This init only works for Linear or Conv layers' \n",
    "\n",
    "    if classname.find('Linear') == 1: \n",
    "        in_features, out_features = layer.weight.shape\n",
    "        classical_weight = classical_weights(out_features, in_features, scale, seed)\n",
    "        layer.weight.data = Tensor(classical_weight)\n",
    "        \n",
    "    elif classname.find('Conv2d') == 1:\n",
    "        assert layer.in_channels == 1, 'This init only works when image has 1 input channel'\n",
    "        out_channels, in_channels, xdim, ydim = layer.weight.shape\n",
    "        classical_weight = classical_weights(out_channels, (xdim, ydim), scale, seed=seed)\n",
    "        layer.weight.data = Tensor(classical_weight.reshape(out_channels, 1, xdim, ydim))\n",
    "        \n",
    "    if bias == False:\n",
    "        layer.bias = None\n",
    "        \n",
    "class classical_RFNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Random Feature network to classify time-series or MNIST digits. The first layer is initialized from GP\n",
    "    with diagonal covariance.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, scale=1, bias=False, seed=None):\n",
    "        super(classical_RFNet, self).__init__()\n",
    "        if type(input_dim) is int: ## for time-series\n",
    "            self.RF_layer = nn.Linear(in_features=input_dim, out_features=hidden_dim) \n",
    "            self.clf = nn.Linear(in_features=hidden_dim, out_features=2)\n",
    "        elif type(input_dim) is tuple: ## for MNIST\n",
    "            self.RF_layer = nn.Conv2d(in_channels=1, out_channels=hidden_dim, kernel_size=28)\n",
    "            self.clf = nn.Conv2d(in_channels=hidden_dim, out_channels=10, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # initialize the first layer\n",
    "        classical_init(self.RF_layer, scale, bias, seed)\n",
    "        self.RF_layer.weight.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.RF_layer(x))\n",
    "        beta = self.clf(h)\n",
    "        return beta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4811e265-4672-44a8-9eec-0951fb885738",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the init\n",
    "linear = nn.Linear(1, 20)\n",
    "classical_init(linear)\n",
    "\n",
    "conv = nn.Conv2d(1, 20, 28)\n",
    "classical_init(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d80f5940-5219-488d-a069-82acaf4d2794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 10])\n"
     ]
    }
   ],
   "source": [
    "## check the model for images\n",
    "images = torch.randn(20, 1, 28, 28)\n",
    "input_dim, hidden_dim = (1, 28, 28), 20\n",
    "model = classical_RFNet(input_dim, hidden_dim=100, bias=False, seed=1)\n",
    "output = model(images)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38aa5ee6-8814-40a6-b927-873adf8a3e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "## check the model for time-series\n",
    "tseries = torch.randn(20, 150)\n",
    "input_dim, hidden_dim = 150, 20\n",
    "model = classical_RFNet(input_dim, hidden_dim=100, bias=False, seed=1)\n",
    "output = model(tseries)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72b3a4-0df1-4b32-9eff-e0f9e6df027e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
